# FEUILLET DE PROMPTS - D√©fi #18 : Le Cadet de Votre √âcole

**D√©fi :** D√©ployer en local la plus petite version de LLM de Gemini  
**Points :** 25 pts  
**Objectif :** Installer et ex√©cuter le mod√®le Gemini le plus l√©ger localement  
**Temps estim√© :** 1h30

---

## üéØ PROMPT 1 : Recherche du mod√®le Gemini le plus l√©ger

**Prompt utilis√© :**
```
Je dois d√©ployer localement la plus petite version du LLM Gemini (Google). 

Recherche et identifie :
1. Quelle est la plus petite version de Gemini disponible pour d√©ploiement local ?
2. Quel est le nombre de param√®tres de ce mod√®le ?
3. Quelles sont les alternatives open-source bas√©es sur Gemini ou similaires ?
4. Quels sont les pr√©requis syst√®me (RAM, GPU, stockage) ?

Fournis une r√©ponse technique d√©taill√©e avec les sources.
```

**R√©sultat obtenu :**

**Gemini Nano** est la plus petite version de Gemini, con√ßue pour fonctionner sur appareils mobiles et localement.

Caract√©ristiques :
- **Param√®tres :** ~1.8B √† 3.25B param√®tres (selon la variante)
- **Versions :** Nano-1 et Nano-2
- **Pr√©requis minimaux :**
  - RAM : 4-8 GB
  - Stockage : ~2-4 GB
  - GPU : Optionnel (CPU suffit)
  - OS : Linux, Android, Chrome OS

**Alternatives pour d√©ploiement local :**
1. **Gemma** (Google) - Open source, d√©riv√© de Gemini
   - Gemma 2B (2 milliards de param√®tres)
   - Gemma 7B (7 milliards de param√®tres)
   
2. **Utilisation via Ollama** :
   - Permet de d√©ployer Gemma localement facilement
   - Interface simple en ligne de commande

---

## üéØ PROMPT 2 : Guide d'installation de Gemma 2B avec Ollama

**Prompt utilis√© :**
```
G√©n√®re un guide complet d'installation √©tape par √©tape pour d√©ployer Gemma 2B (la plus petite version li√©e √† Gemini) en local sur Linux en utilisant Ollama.

Le guide doit inclure :
1. Installation d'Ollama
2. T√©l√©chargement du mod√®le Gemma 2B
3. Commandes de test
4. V√©rification que √ßa fonctionne
5. Exemples d'utilisation

Format : Tutoriel technique avec toutes les commandes Shell n√©cessaires.
```

**R√©sultat obtenu :**

```bash
# GUIDE D'INSTALLATION - GEMMA 2B LOCAL

## √âtape 1 : Installation d'Ollama

# T√©l√©charger et installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# V√©rifier l'installation
ollama --version

## √âtape 2 : T√©l√©charger Gemma 2B

# T√©l√©charger le mod√®le Gemma 2B (plus petit mod√®le)
ollama pull gemma:2b

# Alternative : Gemma 2B en mode instruction-tuned
ollama pull gemma:2b-instruct

## √âtape 3 : Lancer le mod√®le

# D√©marrer Gemma en mode interactif
ollama run gemma:2b

## √âtape 4 : Test du mod√®le

# Dans le prompt Ollama, tester avec :
>>> Bonjour, qui es-tu ?
>>> Explique-moi ce qu'est un r√©seau de neurones en 3 phrases.
>>> /bye  # Pour quitter

## √âtape 5 : Utilisation via API

# Lancer le serveur Ollama
ollama serve

# Tester via API (dans un autre terminal)
curl http://localhost:11434/api/generate -d '{
  "model": "gemma:2b",
  "prompt": "Pourquoi le ciel est-il bleu?",
  "stream": false
}'

## √âtape 6 : Informations sur le mod√®le

# Voir les d√©tails du mod√®le
ollama show gemma:2b

# Lister tous les mod√®les install√©s
ollama list

# Voir l'utilisation de la m√©moire
ollama ps
```

---

## üéØ PROMPT 3 : Script de d√©ploiement automatis√©

**Prompt utilis√© :**
```
Cr√©e un script Bash qui automatise l'installation compl√®te de Gemma 2B avec Ollama, avec :
- V√©rifications des pr√©requis syst√®me
- Installation d'Ollama
- T√©l√©chargement de Gemma 2B
- Tests automatiques
- G√©n√©ration d'un rapport de d√©ploiement

Le script doit √™tre robuste avec gestion d'erreurs.
```

**R√©sultat :** Script `deploy_gemma.sh`

---

## üéØ PROMPT 4 : Documentation technique du d√©ploiement

**Prompt utilis√© :**
```
R√©dige une documentation technique professionnelle (format Markdown) expliquant :

1. Introduction : Pourquoi Gemma 2B ?
2. Architecture du mod√®le
3. Processus de d√©ploiement local
4. Sp√©cifications techniques
5. Cas d'usage
6. Limites et consid√©rations
7. Comparaison avec d'autres LLMs l√©gers

Style : Documentation DevOps professionnelle, 800-1000 mots.
```

**R√©sultat :** Documentation compl√®te dans `documentation/deploiement_gemma.md`

---

## üéØ PROMPT 5 : Exemples d'utilisation et benchmarks

**Prompt utilis√© :**
```
Cr√©e un notebook ou script Python qui :
1. Se connecte au mod√®le Gemma 2B local via l'API Ollama
2. Teste diff√©rents types de prompts (questions, code, cr√©ativit√©)
3. Mesure le temps de r√©ponse
4. Compare les r√©ponses avec et sans streaming
5. G√©n√®re un rapport de performance

Code Python comment√© et document√©.
```

**R√©sultat :** Script `test_gemma.py` avec benchmarks

---

## üìä VALIDATION DU D√âFI

- ‚úÖ Identification du plus petit mod√®le Gemini (Gemma 2B)
- ‚úÖ Installation locale r√©ussie
- ‚úÖ Mod√®le d√©ploy√© et fonctionnel
- ‚úÖ Documentation technique compl√®te
- ‚úÖ Scripts d'automatisation
- ‚úÖ Tests et benchmarks
- ‚úÖ Tout le processus document√©

**Sp√©cifications du mod√®le d√©ploy√© :**
- Nom : Gemma 2B
- Param√®tres : 2 milliards
- Taille : ~1.4 GB
- RAM utilis√©e : ~3-4 GB
- Technologie : D√©riv√© de Gemini (Google)

**Statut :** ‚úÖ VALID√â  
**Points :** 25 pts  
**Temps r√©el :** 1h30

